{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D8zm-QXwsYF0",
        "outputId": "d5c0d75e-9bfd-4c22-9df5-3ff63c2812db"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import time\n",
        "import logging\n",
        "import psutil\n",
        "from torch.amp import autocast, GradScaler\n",
        "from IPython.display import display, Image as IPImage\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR\n",
        "from torch.optim.lr_scheduler import SequentialLR\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    logging.warning(\"No GPU detected. Ensure GPU is enabled in Runtime settings.\")\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "BASE_PATH = '/content/drive/MyDrive/intel_project'\n",
        "SHARP_PATH = os.path.join(BASE_PATH, 'sharp')\n",
        "DEFOCUSED_PATH = os.path.join(BASE_PATH, 'defocused_blurred')\n",
        "MOTION_PATH = os.path.join(BASE_PATH, 'motion_blurred')\n",
        "RESULTS_DIR = os.path.join(BASE_PATH, 'results')\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Custom Dataset with Fallback for Missing Defocused Images\n",
        "class ImageTripletDataset(Dataset):\n",
        "    def __init__(self, sharp_dir, defocused_dir, motion_dir, transform=None, augment_transform=None):\n",
        "        self.sharp_dir = sharp_dir\n",
        "        self.defocused_dir = defocused_dir\n",
        "        self.motion_dir = motion_dir\n",
        "        self.transform = transform\n",
        "        self.augment_transform = augment_transform\n",
        "        self.image_ids = []\n",
        "\n",
        "        sharp_files = [f for f in os.listdir(sharp_dir) if f.endswith(('.jpg', '.jpeg'))]\n",
        "        for f in sharp_files:\n",
        "            if f.rsplit('_', 1)[-1] in ['S.jpg', 'S.jpeg']:\n",
        "                base_id = f.rsplit('_', 1)[0]\n",
        "                ext = f.split('.')[-1]\n",
        "                sharp_path = os.path.join(sharp_dir, f\"{base_id}_S.{ext}\")\n",
        "                defocused_path = os.path.join(defocused_dir, f\"{base_id}_F.{ext}\")\n",
        "                motion_path = os.path.join(motion_dir, f\"{base_id}_M.{ext}\")\n",
        "\n",
        "                # Require only sharp image; use sharp as fallback for defocused if missing\n",
        "                if os.path.exists(sharp_path):\n",
        "                    self.image_ids.append((base_id, ext))\n",
        "                    if not os.path.exists(defocused_path):\n",
        "                        logging.warning(f\"Missing defocused image for {base_id}, using sharp as fallback\")\n",
        "                    if not os.path.exists(motion_path):\n",
        "                        logging.warning(f\"Missing motion image for {base_id}\")\n",
        "\n",
        "        if not self.image_ids:\n",
        "            raise ValueError(\"No valid sharp images found.\")\n",
        "\n",
        "        logging.info(f\"Found {len(self.image_ids)} valid sharp images for triplets.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        base_id, ext = self.image_ids[idx]\n",
        "\n",
        "        sharp_path = os.path.join(self.sharp_dir, f\"{base_id}_S.{ext}\")\n",
        "        defocused_path = os.path.join(self.defocused_dir, f\"{base_id}_F.{ext}\")\n",
        "        motion_path = os.path.join(self.motion_dir, f\"{base_id}_M.{ext}\")\n",
        "\n",
        "        try:\n",
        "            sharp_img = Image.open(sharp_path).convert('RGB')\n",
        "            # Use sharp as fallback if defocused is missing\n",
        "            if os.path.exists(defocused_path):\n",
        "                defocused_img = Image.open(defocused_path).convert('RGB')\n",
        "            else:\n",
        "                defocused_img = sharp_img.copy()\n",
        "            motion_img = Image.open(motion_path).convert('RGB') if os.path.exists(motion_path) else sharp_img.copy()\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load images for {base_id}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        sharp_img = sharp_img.resize((640, 360), Image.BICUBIC)\n",
        "        defocused_img = defocused_img.resize((640, 360), Image.BILINEAR)\n",
        "        motion_img = motion_img.resize((640, 360), Image.BILINEAR)\n",
        "\n",
        "        if self.augment_transform:\n",
        "            # Apply augmentation to all images consistently\n",
        "            seed = torch.randint(0, 100000, (1,)).item()\n",
        "            torch.manual_seed(seed)\n",
        "            sharp_img = self.augment_transform(sharp_img)\n",
        "            torch.manual_seed(seed)\n",
        "            defocused_img = self.augment_transform(defocused_img)\n",
        "            torch.manual_seed(seed)\n",
        "            motion_img = self.augment_transform(motion_img)\n",
        "\n",
        "        if self.transform:\n",
        "            sharp_img = self.transform(sharp_img)\n",
        "            defocused_img = self.transform(defocused_img)\n",
        "            motion_img = self.transform(motion_img)\n",
        "\n",
        "            if torch.isnan(sharp_img).any() or torch.isinf(sharp_img).any() or \\\n",
        "               torch.isnan(defocused_img).any() or torch.isinf(defocused_img).any() or \\\n",
        "               torch.isnan(motion_img).any() or torch.isinf(motion_img).any():\n",
        "                logging.error(f\"Invalid tensor values for {base_id}\")\n",
        "                return None\n",
        "\n",
        "        return sharp_img, defocused_img, motion_img\n",
        "\n",
        "# Perceptual Loss\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        vgg = models.vgg16(pretrained=True).features\n",
        "        self.slice1 = nn.Sequential(*vgg[:4]).eval()\n",
        "        self.slice2 = nn.Sequential(*vgg[4:9]).eval()\n",
        "        self.criterion = nn.MSELoss()\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x = (x * 0.5 + 0.5).clamp(0, 1)\n",
        "        y = (y * 0.5 + 0.5).clamp(0, 1)\n",
        "        x_s1 = self.slice1(x)\n",
        "        y_s1 = self.slice1(y)\n",
        "        x_s2 = self.slice2(x_s1)\n",
        "        y_s2 = self.slice2(y_s1)\n",
        "        loss = self.criterion(x_s1, y_s1) + self.criterion(x_s2, y_s2)\n",
        "        return loss\n",
        "\n",
        "# EDSR Model\n",
        "class EDSR(nn.Module):\n",
        "    def __init__(self, scale_factor=2, pretrained=False):\n",
        "        super(EDSR, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.res_blocks = nn.Sequential(*[self.make_res_block(64) for _ in range(16)])\n",
        "        self.conv2 = nn.Conv2d(64, 64 * (scale_factor ** 2), kernel_size=3, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
        "        self.conv3 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if pretrained:\n",
        "            logging.info(\"Pre-trained EDSR not implemented; using custom initialization.\")\n",
        "        else:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def make_res_block(self, channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = (x * 0.5 + 0.5).clamp(0, 1)  # Denormalize\n",
        "        residual = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.res_blocks(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        residual = F.interpolate(residual, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = self.conv3(x)\n",
        "        x = x + residual\n",
        "        x = x.clamp(0, 1)\n",
        "        x = (x - 0.5) / 0.5  # Normalize to [-1, 1]\n",
        "        return x\n",
        "\n",
        "# Simplified Student Model\n",
        "class StudentModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.res_blocks = nn.Sequential(*[self.make_res_block(64) for _ in range(2)])  # Reduced blocks\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.conv5 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        self.skip_conv = nn.Conv2d(3, 64, kernel_size=1)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def make_res_block(self, channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        skip = self.skip_conv(x)\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.dropout(x + skip)\n",
        "        x = self.res_blocks(x)\n",
        "        x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.conv5(x)\n",
        "        x = x + 0.1 * residual\n",
        "        return x\n",
        "\n",
        "# Teacher Model\n",
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        self.model = EDSR(scale_factor=2, pretrained=False)  # Set to True if pre-trained weights available\n",
        "        self.model.eval()\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(x)\n",
        "            if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
        "                logging.warning(\"NaN/Inf in teacher output, using input as fallback\")\n",
        "                outputs = x\n",
        "        return outputs\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((360, 640)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "])\n",
        "\n",
        "# Dataset and DataLoader\n",
        "try:\n",
        "    dataset = ImageTripletDataset(SHARP_PATH, DEFOCUSED_PATH, MOTION_PATH, transform=transform, augment_transform=augment_transform)\n",
        "except ValueError as e:\n",
        "    logging.error(str(e))\n",
        "    exit(1)\n",
        "\n",
        "filtered_dataset = []\n",
        "for i in range(len(dataset)):\n",
        "    sample = dataset[i]\n",
        "    if sample is not None:\n",
        "        filtered_dataset.append(sample)\n",
        "    else:\n",
        "        logging.warning(f\"Skipping invalid sample at index {i}\")\n",
        "\n",
        "if not filtered_dataset:\n",
        "    logging.error(\"No valid samples in dataset\")\n",
        "    exit(1)\n",
        "\n",
        "logging.info(f\"Total valid samples after filtering: {len(filtered_dataset)}\")\n",
        "train_size = int(0.8 * len(filtered_dataset))\n",
        "test_size = len(filtered_dataset) - train_size\n",
        "logging.info(f\"Train size: {train_size}, Test size: {test_size}\")\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(filtered_dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logging.info(f\"Using device: {device}\")\n",
        "\n",
        "teacher_model = TeacherModel().to(device)\n",
        "student_model = StudentModel().to(device)\n",
        "perceptual_loss = PerceptualLoss().to(device)\n",
        "\n",
        "# Mixed precision scaler\n",
        "scaler = GradScaler('cuda')\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion_mse = nn.MSELoss()\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=0.0005)\n",
        "warmup_scheduler = LinearLR(optimizer, start_factor=0.1, total_iters=5)\n",
        "main_scheduler = CosineAnnealingLR(optimizer, T_max=70)\n",
        "scheduler = SequentialLR(optimizer, [warmup_scheduler, main_scheduler], [5])\n",
        "\n",
        "# Training Loop\n",
        "def train_model(epochs=75):\n",
        "    student_model.train()\n",
        "    teacher_model.eval()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        valid_batches = 0\n",
        "        for sharp_imgs, defocused_imgs, motion_imgs in train_loader:\n",
        "            sharp_imgs, defocused_imgs = sharp_imgs.to(device), defocused_imgs.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast('cuda'):\n",
        "                with torch.no_grad():\n",
        "                    teacher_out = teacher_model(defocused_imgs)\n",
        "                    if torch.isnan(teacher_out).any() or torch.isinf(teacher_out).any():\n",
        "                        logging.warning(f\"Invalid teacher output for batch {valid_batches}, skipping\")\n",
        "                        continue\n",
        "                    teacher_out = F.interpolate(teacher_out, size=(360, 640), mode='bilinear', align_corners=False)\n",
        "\n",
        "                student_out = student_model(defocused_imgs)\n",
        "                loss_mse = criterion_mse(student_out, sharp_imgs)\n",
        "                loss_teacher = criterion_mse(student_out, teacher_out)\n",
        "                loss_perceptual = perceptual_loss(student_out, sharp_imgs)\n",
        "                loss = 0.5 * loss_mse + 0.2 * loss_teacher + 0.3 * loss_perceptual\n",
        "\n",
        "                if torch.isnan(loss_mse) or torch.isnan(loss_teacher) or torch.isnan(loss_perceptual):\n",
        "                    logging.warning(f\"NaN detected: MSE={loss_mse.item()}, Teacher={loss_teacher.item()}, Perceptual={loss_perceptual.item()}\")\n",
        "                    continue\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            running_loss += loss.item()\n",
        "            valid_batches += 1\n",
        "\n",
        "            del teacher_out, student_out\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        if valid_batches == 0:\n",
        "            logging.error(\"No valid batches processed in epoch\")\n",
        "            return\n",
        "\n",
        "        avg_loss = running_loss / valid_batches\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "        scheduler.step()\n",
        "\n",
        "    torch.save(student_model.state_dict(), os.path.join(RESULTS_DIR, \"student_model.pth\"))\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model():\n",
        "    student_model.eval()\n",
        "    ssim_scores = []\n",
        "    psnr_scores = []\n",
        "    inference_times = []\n",
        "    sample_images = []\n",
        "\n",
        "    for i, (sharp_imgs, defocused_imgs, motion_imgs) in enumerate(test_loader):\n",
        "        sharp_imgs, defocused_imgs = sharp_imgs.to(device), defocused_imgs.to(device)\n",
        "\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad(), autocast('cuda'):\n",
        "            sharpened_imgs = student_model(defocused_imgs)\n",
        "        inference_time = time.time() - start_time\n",
        "        inference_times.append(inference_time)\n",
        "\n",
        "        sharp_np = sharp_imgs.cpu().numpy().transpose(0, 2, 3, 1)\n",
        "        sharpened_np = sharpened_imgs.cpu().numpy().transpose(0, 2, 3, 1)\n",
        "        sharp_np = (sharp_np * 0.5 + 0.5).clip(0, 1)\n",
        "        sharpened_np = (sharpened_np * 0.5 + 0.5).clip(0, 1)\n",
        "\n",
        "        for j in range(sharp_np.shape[0]):\n",
        "            logging.debug(f\"Sharp image {i}_{j}: min={sharp_np[j].min():.4f}, max={sharp_np[j].max():.4f}\")\n",
        "            logging.debug(f\"Sharpened image {i}_{j}: min={sharpened_np[j].min():.4f}, max={sharpened_np[j].max():.4f}\")\n",
        "            ssim_score = ssim(sharp_np[j], sharpened_np[j], channel_axis=2, data_range=1.0)\n",
        "            psnr_score = psnr(sharp_np[j], sharpened_np[j], data_range=1.0)\n",
        "            ssim_scores.append(ssim_score)\n",
        "            psnr_scores.append(psnr_score)\n",
        "\n",
        "            if i * 1 + j < 2 and len(sample_images) < 2:\n",
        "                sharp_path = os.path.join(RESULTS_DIR, f\"sharp_{i}_{j}.png\")\n",
        "                sharpened_path = os.path.join(RESULTS_DIR, f\"sharpened_{i}_{j}.png\")\n",
        "                defocused_path = os.path.join(RESULTS_DIR, f\"defocused_{i}_{j}.png\")\n",
        "                sharp_img_uint8 = (sharp_np[j] * 255).astype(np.uint8)\n",
        "                sharpened_img_uint8 = (sharpened_np[j] * 255).astype(np.uint8)\n",
        "                defocused_np = defocused_imgs.cpu().numpy().transpose(0, 2, 3, 1)\n",
        "                defocused_np = (defocused_np * 0.5 + 0.5).clip(0, 1)\n",
        "                defocused_img_uint8 = (defocused_np[j] * 255).astype(np.uint8)\n",
        "                cv2.imwrite(sharp_path, cv2.cvtColor(sharp_img_uint8, cv2.COLOR_RGB2BGR))\n",
        "                cv2.imwrite(sharpened_path, cv2.cvtColor(sharpened_img_uint8, cv2.COLOR_RGB2BGR))\n",
        "                cv2.imwrite(defocused_path, cv2.cvtColor(defocused_img_uint8, cv2.COLOR_RGB2BGR))\n",
        "                logging.info(f\"Saved sharp image to {os.path.abspath(sharp_path)}\")\n",
        "                logging.info(f\"Saved sharpened image to {os.path.abspath(sharpened_path)}\")\n",
        "                logging.info(f\"Saved defocused image to {os.path.abspath(defocused_path)}\")\n",
        "                sample_images.append((sharp_np[j], sharpened_np[j], defocused_np[j]))\n",
        "                print(f\"Sample {i*1+j+1} (SSIM: {ssim_score:.4f}, PSNR: {psnr_score:.4f}):\")\n",
        "                plt.figure(figsize=(15, 5))\n",
        "                plt.subplot(1, 3, 1)\n",
        "                plt.title(\"Defocused\")\n",
        "                plt.imshow(defocused_np[j])\n",
        "                plt.axis('off')\n",
        "                plt.subplot(1, 3, 2)\n",
        "                plt.title(\"Sharp\")\n",
        "                plt.imshow(sharp_np[j])\n",
        "                plt.axis('off')\n",
        "                plt.subplot(1, 3, 3)\n",
        "                plt.title(\"Sharpened\")\n",
        "                plt.imshow(sharpened_np[j])\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "    avg_ssim = np.mean(ssim_scores)\n",
        "    avg_psnr = np.mean(psnr_scores)\n",
        "    avg_fps = 1 / np.mean(inference_times)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(ssim_scores, label='SSIM Score per Image')\n",
        "    plt.axhline(y=avg_ssim, color='r', linestyle='--', label=f'Average SSIM: {avg_ssim:.4f}')\n",
        "    plt.xlabel('Test Image Index')\n",
        "    plt.ylabel('SSIM Score')\n",
        "    plt.title('SSIM Scores on Test Dataset')\n",
        "    plt.legend()\n",
        "    ssim_plot_path = os.path.join(RESULTS_DIR, 'ssim_scores.png')\n",
        "    plt.savefig(ssim_plot_path)\n",
        "    plt.close()\n",
        "    display(IPImage(ssim_plot_path))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(psnr_scores, label='PSNR Score per Image')\n",
        "    plt.axhline(y=avg_psnr, color='r', linestyle='--', label=f'Average PSNR: {avg_psnr:.4f}')\n",
        "    plt.xlabel('Test Image Index')\n",
        "    plt.ylabel('PSNR Score')\n",
        "    plt.title('PSNR Scores on Test Dataset')\n",
        "    plt.legend()\n",
        "    psnr_plot_path = os.path.join(RESULTS_DIR, 'psnr_scores.png')\n",
        "    plt.savefig(psnr_plot_path)\n",
        "    plt.close()\n",
        "    display(IPImage(psnr_plot_path))\n",
        "\n",
        "    return avg_ssim, avg_psnr, avg_fps, sample_images\n",
        "\n",
        "# Generate Report\n",
        "def generate_report(avg_ssim, avg_psnr, avg_fps, sample_images):\n",
        "    report = f\"\"\"\n",
        "# Image Sharpening Model Report\n",
        "\n",
        "## Data Sources\n",
        "- **Dataset**: Custom dataset with {len(dataset)} sharp images (defocused images missing for most triplets).\n",
        "- **Paths**:\n",
        "  - Sharp: {SHARP_PATH}\n",
        "  - Defocused: {DEFOCUSED_PATH}\n",
        "  - Motion: {MOTION_PATH}\n",
        "- **Teacher Model**: Custom EDSR\n",
        "\n",
        "## Model Description\n",
        "\n",
        "### Teacher Model\n",
        "- **Architecture**: EDSR with 16 residual blocks.\n",
        "- **Parameters**: ~1M.\n",
        "- **Role**: Provides stable sharpened outputs.\n",
        "\n",
        "### Student Model\n",
        "- **Architecture**: Simplified CNN with 5 layers, 2 residual blocks, skip connections, and residual connection.\n",
        "  - Conv1: 3 -> 64, Conv2: 64 -> 64, ResBlocks: 64 -> 64 (x2), Conv3: 64 -> 128, Conv4: 128 -> 64, Conv5: 64 -> 3.\n",
        "  - Skip connection: Conv 3 -> 64, Dropout: 0.1.\n",
        "- **Parameters**: ~50K.\n",
        "- **Role**: Lightweight sharpening.\n",
        "\n",
        "## Training Process\n",
        "- **Dataset Split**: {train_size} train, {test_size} test.\n",
        "- **Preprocessing**: Resize to 640x360, data augmentation (flips, rotation).\n",
        "- **Loss**: 0.5 * MSE, 0.2 * Teacher MSE, 0.3 * Perceptual.\n",
        "- **Optimizer**: Adam, lr=0.0005, LinearWarmupCosineAnnealingLR.\n",
        "- **Epochs**: 75.\n",
        "\n",
        "## Performance Analysis\n",
        "- **SSIM**: {avg_ssim:.4f} (target > 0.90).\n",
        "- **PSNR**: {avg_psnr:.4f} (target > 30.0).\n",
        "- **FPS**: {avg_fps:.2f} (target 30-60).\n",
        "- **Test Dataset**: {len(test_dataset)} images.\n",
        "\n",
        "## Results\n",
        "- **SSIM Plot**: {RESULTS_DIR}/ssim_scores.png.\n",
        "- **PSNR Plot**: {RESULTS_DIR}/psnr_scores.png.\n",
        "- **Sample Images**: {RESULTS_DIR}/sharp_*.png, sharpened_*.png, defocused_*.png.\n",
        "- **Model**: {RESULTS_DIR}/student_model.pth.\n",
        "\n",
        "## Conclusion\n",
        "SSIM {avg_ssim:.4f}, PSNR {avg_psnr:.4f}, FPS {avg_fps:.2f}. Dataset issues (missing defocused images) severely impacted performance.\n",
        "\"\"\"\n",
        "    with open(os.path.join(RESULTS_DIR, \"sharpening_report.md\"), \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Training model...\")\n",
        "    train_model(epochs=75)\n",
        "\n",
        "    print(\"Evaluating model...\")\n",
        "    avg_ssim, avg_psnr, avg_fps, sample_images = evaluate_model()\n",
        "\n",
        "    print(\"Generating report...\")\n",
        "    generate_report(avg_ssim, avg_psnr, avg_fps, sample_images)\n",
        "\n",
        "    print(f\"Results saved in {RESULTS_DIR}\")\n",
        "    print(f\"Average SSIM: {avg_ssim:.4f}, Average PSNR: {avg_psnr:.4f}, Average FPS: {avg_fps:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
